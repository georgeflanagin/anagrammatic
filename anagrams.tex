\documentclass[letterpaper, 11pt]{article}
\usepackage{cmap}
\usepackage{urtechdoc}

\SetWatermarkText{Work in Process}
\SetWatermarkFontSize{4cm}
\SetWatermarkAngle{55}
\SetWatermarkColor[gray]{0.92}

\title{A Minimal Algorithm to Find Anagrams Using Python}
\author{George Flanagin\\University of Richmond\\\lit{gflanagin@richmond.edu}}
\date{\today}

\setlength{\parskip}{0.8em}
\setlength{\parindent}{0.8em}

\newcommand{\D}{$\mathfrak{D}$\xspace}
\newcommand{\Dp}{$\mathfrak{D}'$\xspace}
\newcommand{\Dpp}{$\mathfrak{D}''$\xspace}
\newcommand{\w}{$w$\xspace}
\newcommand{\aw}{$\overrightarrow{w}$\xspace}
\newcommand{\awp}{$\overrightarrow{w'}$\xspace}
\newcommand{\ra}{$\overrightarrow{r}$\xspace}
\newcommand{\rap}{$\overrightarrow{r'}$\xspace}


\begin{document}
\maketitle
\begin{abstract}
Anagrams are fun and difficult. They are an excellent way to explore
Python's data structures, and an excuse to develop a few new ones
expressly for this purpose. This paper defines an efficient algorithm
for finding all anagrams of a given collection of letters using the
Python Standard Library for the base code, and the system dictionary
as a source for allowed words.

\end{abstract}

\tableofcontents
\listoffigures

\newpage
\pagewiselinenumbers
\section{Getting started}
\quickquote{Of course just about every pronounceable combination
of five letters has been used to spell or misspell something somewhere, at
some point in history.}{Donald E. Knuth, 2011\\\emph{Combinatorial
Algorithms, Part 1}, p. 519\\answer to Problem 25 in Section 7}

\subsection{Definitions}
My interest in anagrams started fairly late in life. An episode of
\emph{The Simpsons} named ``Lisa's Rival'' aired 11 September 1994,
and in it Lisa goes to house of a new girl in the school, Allison
Taylor. At Allison's house, Lisa is asked to join the Taylors in a
specialized game of anagrams in which the names of famous people
are rearranged to form descriptive anagrams: \emph{Alec Guinness}
becomes \emph{genuine class}.  Lisa was overwhelmed.

To avoid offending or upsetting readers, I will be using my own
name as the basis for the examples in this paper. Mercifully for
the contruction of examples, my name consists only of common letters
in English, and it has a useful proportion of vowels. Throughout
this paper, we will call the original phrase for which we seek
anagrams the \emph{target phrase}, or just the \emph{target}.

To begin, we must have a definition of an anagram. The always used
preposition \emph{of} features in our definition, because anagrams
always appear in pairs.  It makes no sense to say ``\emph{George
Flanagin} is an anagram," without stating its partner phrase, the
most descriptive of which may be \emph{long fearing age}. 

The technical properties of an anagram are:

\begin{enumerate}
\item Two phrases are anagrams of each other if they contain the
same set of letters. In the case of \emph{George Flanagin}, its
anagrams must have exactly three \emph{g}-s, two each of \emph{a},
\emph{e}, and \emph{n}, and one each of \emph{f}, \emph{i}, \emph{l},
\emph{o}, and \emph{r}.  Fourteen letters.

\item Anagrams must consist of complete words in some dictionary.
Exactly which dictionary is a point of {\ae}sthetics, as is whether
one should consider single letter words such as \lit{a} in English
and Spanish, \lit{I} in English, and \lit{y}, \lit{o} in Spanish,
and other oddities like apostrophes and diacritics.

\item Additional rules are sometimes applied. Common constraints are:

\begin{itemize}
\item A maximum number of words in the anagrams of the original phrase.

\item The elimination or inclusion of proper nouns in the derived
anagrams.

\item A lack of words shared with the original phrase.
\end{itemize}
\end{enumerate}

Fortunately, none of the above boundaries is difficult to selectively
enforce in a program. 

\subsection{The big picture of the search}

At first, the search seems terribly complicated, and it is certainly
not trivial. Everyone who has dealt with combinatorics knows how
quickly the the number of subsets grows, $16383$ in the case of
fourteen letters, and the number of partitions, the fourteenth Bell
number, is $27644437$.\footnote{The Bell numbers are OEIS sequence
A000110, \lit{https://oeis.org/A000110}}

The constraint is the dictionary. The largest one generally used
in computing is the list of words that ships as the spelling
dictionary with Linux, and it has a mere $479826$ words. In any
search for anagrams except \emph{the quick brown fox jumped over
the lazy dog}, we will eliminate all the words that contain any
letter not found in the target. In the case of our example, we can
eliminate not only all the words that begin with $[b-d,h,j,k,m,n,p,q,s-z]$,
but all the words that contain even one of those letters. Doing no
programming at all, we can put the upper limit on the number of
words to examine as $2777$ if only lower case words are considered,
and $5032$ if we allow words that normally have capitals in
English.\footnote{These numbers are the results of the two na\"ive
regular expression searches of the Linux spelling dictionary with
\lit{\textasciicircum[aegnfilor]\textbackslash+\$} in case sensitive
and case insensitive modes.} These are the upper bounds, because
the figures are not derived by looking for the words that have no
more of each letter than are found in the target.

For many programmers, the following is a useful abstraction to
consider how we go about constructing both \emph{an} anagram, and
\emph{all} anagrams.  Consider the target phrase and bit-string of
the same length. In Figure~\ref{fig:bitmask}, we see two anagrams,
\emph{george}+\emph{flanagin} and \emph{long}+\emph{fearing}+\emph{age},
where each character is ($1$) or is not ($0$) used. For both of the
anagrams, there is exactly one $1$ in each column, and this tabulation
is similar to the way that you might search for anagrams with a
pile of Scrabble\CircleR\xspace letters. The equivalent big endian
numeric represenations are shown in the right column.

\begin{figure}
\begin{center}
\begin{tabular}{lccccccccccccccr}
\toprule
 &g&e&o&r&g&e&f&l&a&n&a&g&i&n&\\
\midrule
george&1&1&1&1&1&1&0&0&0&0&0&0&0&0&16128\\
flanagin&0&0&0&0&0&0&1&1&1&1&1&1&1&1&255\\
\midrule
long&1&0&1&0&0&0&0&1&0&1&0&0&0&0&10320\\
fearing&0&1&0&1&1&0&1&0&1&0&0&0&1&1&5795\\
age&0&0&0&0&0&1&0&0&0&0&1&1&0&0&268\\
\bottomrule
\end{tabular}
\caption{The relationship between anagrams and bit masks}
\label{fig:bitmask}
\end{center}
\end{figure}

\begin{figure}
\begin{tabular}{lp{0.8\textwidth}}
\toprule
Symbol&Use and meaning\\
\midrule
$w$, $w_n$&word or words from a dictionary.\\

$\mathfrak{S}$, $\mathfrak{T}$&phrases for which are finding anagrams.\\

$\overrightarrow{w}$, $\overrightarrow{\mathfrak{S}}$&representations
of $w$ and $\mathfrak{S}$ where the letters have been sorted. In
the programming section, we will be using a standard lexical sort,
but this is unimportant as long as the same sort-order is used
throughout. If $w$ is \lit{loaf}, then $\overrightarrow{w}$ is
\lit{aflo}.\\

$w \leq \mathfrak{S}$&This expression is true iff $w$ can be
constructed from the letters in $\mathfrak{S}$. For example \lit{foal}
$\leq$ \lit{georgeflanagin}, and \lit{foal} $\leq$ \lit{loaf}. Note
that this expression is true or false without regard to whether the
letters in each term have been sorted.\\


$w_1 \oplus w_2$&The result is a collection of all the letters in
the two words, without preserving the order of the letters in each
word. The $\oplus$ operator was chosen over $+$ because the bare
plus sign is used as a string concatentation operator in many
programming languages, including Python.\\

$w_1 \ominus w_2$&As with the $oplus$ operation above, except that
we are removing all the letters in $w_2$ from $w_1$. This operation
is only defined (or meaningful) iff $w_2 \leq w_1$, otherwise in
the grammar of anagrams (anagrammar?), the statement is like dividing
by zero.\\

$w_1 \odot w_2$&This expression is true iff $w_1$ and $w_2$ are
anagrams, so expanding on the above examples, \lit{foal} $\odot$
\lit{loaf} is true, as is:

$($\lit{long} $\oplus$ \lit{fearing} $\oplus$ \lit{age}$)$ $\odot$
\lit{georgeflanagin}.\\

$r$, $r_n$&$r$ is for remainder, so when we perform a $\ominus$
operation, the result will be a value expressed as an $r$, so $r_1
= \mathfrak{S} \ominus w_1$\\

\D, \Dp, \emph{etc}.&Throughout, we will use \D to represent the
core dictionary, and \Dp and \Dpp to represent derived dictionaries
such that \Dpp $\subset$ \Dp $\subset$ \D, in other words, a filter.\\

\bottomrule
\end{tabular}
\caption{Symbols used to discuss anagrams}
\label{fig:anagramsymbols}
\end{figure}

\section{Notation}
\quickquote{The number of systems of terminology presently used in
graph theory is equal to a close approximation of the number of
graph theorists.}{Richard P. Stanley\\\emph{Enumerative
Combinatorics}\\Cambridge University Press, 1986}

Anagrams suffer from their essence being relatively easy to state
in English, yet having no obvious representation in symbols. Given
that programming languages are a type of symbolic representation,
we will benefit from having a strong symbolic notation for anagrams,
their parts, and their construction.

In Figure~\ref{fig:anagramsymbols} we can see the basic notation
that is invented for the purpose of this discussion. The other
symbols used, such as assignment, absolute value, and non-anagram
set operations, are expressed in conventional notation, and will
mean what you expect them to.

The notation suggests that our Python representation will need all
of these operators/operations:

\begin{enumerate}
\item Sorting the letters of a string to make an new string of the 
same length.

\item The always useful ``partial ordering'' operator, $\leq$, so that
we can determine if words can be used to make an anagram of the target
phrase.

\item A method to combine strings beyond concatenation, and a method
to remove letters from a string.

\item A method to filter the useful words in a dictionary to make
a new, subset dictionary.

\item A method of bookkeeping to allow us to track the anagrams that
have been found, and avoid searching the same path twice.
\end{enumerate}

In fact, these operations lead us directly to a discussion of the 
algorithm to find all anagrams. 

\section{Algorithm}

\quickquote{Homer Jay, how do you keep your hair so rich and full?\\
Lather, rinse, and repeat. Always repeat.}{Homer Simpson\\D'oh-in'
in the Wind\\15 November 1998}

Given the small number of qualifying words, and the vast available
memory combined with the computational abilities of even bottom-self
computers, finding all anagrams of a phrase could be done by brute
force. That approach is not very satisfying. Instead, we are searching
for elegance and comprehension, two nouns that often appear
side-by-side.

\subsection{Pruning the dictionary}

Our first step is the elimination of all the words that are made
from incompatible collections of letters. In our grammar, we seek
to construct

\begin{equation}
\label{eq:deriveddictionaries}
\mathfrak{D}' := \{w:w \leq \mathfrak{S} \wedge w \in \mathfrak{D}\}
\end{equation}

This is often a small collection of words, and we know that 

\begin{equation}
\label{eq:wordlength}
\forall w: |w| \leq |\mathfrak{S}|
\end{equation}


\subsection{Trying the words}

It makes sense to start with the longest words in \Dp, a fact that
will guide us when we start the programming in the next section.
Each word in the dictionary will be subtracted from the target
phrase, and will leave a complementary set of remainders.

\begin{equation}
\label{eq:remainders}
\mathfrak{R} = \{\forall w : \mathfrak{S} \ominus w \}
\end{equation}

Equation~\ref{eq:remainders} is well suited to the list comprehension
construct in Python.

At this point, we should also take note of the one-to-many relationship
between \aw and the dictionary words \w. Words that are anagrams
of each other share the same sorted representation of their letters,
so in a key-value look up table, if the keys are of the form \aw,
then they must support a list (tuple) of one or more \w-s as the
values.

While programming this data structure takes us into the shallow end
of the pool of rolling our own data structures later on, it does
mean that we do not need to try any of the words in the tuple to
make an anagram, we need only concern ourselves with the sorted
key. Consider this specific case: $acer \longrightarrow \{acre,
race, care\}$

The sorted representation, $acer$, is meaningless. But we can freely
substitute any of the three English words in anagrams that contain
one of them. Whether the collection of real words associated with
a key is one or more than one, we only need to bother with the key.
Thus, Equation~\ref{eq:remainders} becomes the more manageable
expression seen here:

\begin{equation}
\mathfrak{R} = \{\forall \overrightarrow{w} : \mathfrak{S} \ominus \overrightarrow{w} \}
\end{equation}

We cannot neglect the fact that $\forall w: w \odot w$, or in plain English,
every word is an anagram of itself, so we must check to see whether each
remainder is a key in the dictionary and a complement of some other
key in the same dictionary. So before any recursive decent begins, we 
must check for the ``two word'' solution.

\subsection{Recursion and bookkeeping}

At this point, we have the algorithm reasonably well in mind, if not
in hand. We take our collection of remainders and derive \Dpp from \Dp,
and reapply the testing of all the keys in \Dpp to $\mathfrak{R}$.
Practially speaking, the dictionary rapidly becomes small. 

Additionally, we can exploit the fact that we are keeping track of
the \aw terms as we go to ensure that we do not test them more than
once, and this is where bookkeeping enters the picture. It seems
fairly natural to think of this as a forest of $n$-ary trees, where
the root node of each is a \aw term. For \aw terms that offer no
completion (\ie dead ends) we can saw these to the ground, and
experience has shown that dead ends will constitute the majority
of the \aw terms we try.

\section{Programming}

This paper is being written in 2020, so the programming is definitely
done using Python~3. At this time, I am using Python 3.8, although
I do not think any of the features that first appear in Python 3.8
(such as the ``walrus operator,'' \lit{:=} ) are used in the code
that appears here.

This is a paper about anagrams, Python's data structures, and rolling
a few of our own data structures. It is not about PEP-8 style, sane
exception handling, type hints, nor how to organize code modules
in the project. With that warning, let's get started.

\subsection{Style of the dictionary}

The familiar \verb|/usr/share/dict/linux.words| file has a number
of entries we do not need. There are words with punctuation, and
acronyms that are all caps. I have chosen to eliminate a large
number of the dictionary entries by reading it this way which rids
us of duplicates, capital letters, and punctuation all at once:

\begin{samepage}
\begin{quote}
\small
\begin{verbatim}
with open(dictionary_name, 'r') as infile:
    dictionary_words = set([ _ for _ in 
        [ w.lower() for w in infile.read().split() if w.isalpha() ] 
        ])
\end{verbatim}
\end{quote}
\end{samepage}

There is no need to re-read it with each execution of a search
operation because we can build the type of dictionaries we need,
and save them to disc as \lit{pickle} files that are ready to use.
As a consequence of this ``once through'' operation, there is no
need to optimize the code by which we eliminate the duplicates.

A more interesting and consequential decision is choosing the
organization of the dictionaries. I refer to \emph{dictionaries}
rather than \emph{dictionary} because we need two:

\begin{enumerate}
\item a \lit{dict} (dictionary) whose keys are the words we have
in some way read from the dictionary file, and whose values are the
sorted strings of the letters in the word.

\begin{samepage}
\begin{quote}
\small
\begin{verbatim}
words = ('foal', 'loaf')
sorted_word = 'aflo'
d = { words[0] : sorted_word, words[1] : sorted_word }
\end{verbatim}
\end{quote}
\end{samepage}



\item a \lit{dict} whose keys are the sorted strings from above,
and whose values are a set$\slash$tuple of all the words from the
dictionary that can be made from this string of letters.

\begin{samepage}
\begin{quote}
\small
\begin{verbatim}
d_reversed = { sorted_word : words }
\end{verbatim}
\end{quote}
\end{samepage}

\end{enumerate} 

From the standpoint of use in dictionaries, it is required that
both the keys and values be hashable, because the values become the
keys in the reversed dictionary. Consequently, we cannot use a
sorted list of letters; it must be a string.


\subsection{Going from words to sorted strings}

In the Python Standard Library there are wonders, and one of the
ones we will be using is \lit{collections}, and within it we will
start with the handy \lit{Counter} class. As the documentation
states, \lit{Counter} is a type of \lit{dict}.\footnote{The
documentation referred to here and throughout this paper is the
collection of web pages at \lit{docs.python.org}.  It is searchable,
well written, and accurate. You should not only use it, you should
prefer it.}

Referring to Figure~\ref{fig:anagramsymbols}, we can see that 

\begin{quote}
\small
\begin{verbatim}
>>> S = 'george flanagin'
>>> sorted_S = str(sorted([ _ for _ in S if _ != ' ' ]))
>>> counted_S = collections.Counter(S)
>>> counted_S
Counter({'g': 3, 'e': 2, 'a': 2, 'n': 2, 'o': 1, 'r': 1, 
    'f': 1, 'l': 1, 'i': 1})
\end{verbatim}
\end{quote}

\lit{Counter} defines a number of operations that are very close
to ideal for our use in abstracted algebra to deal with anagrams.
This is good in that we get a head start, but we do need to put in
a bit of work to customize the \lit{Counter} for our purposes.  The
most direct route is the exploitation of Python's underlying object
model.

\lit{Counter} gives us a useful iterator named \lit{elements()} that
we can pass directly to the \lit{sorted} builtin.  

\begin{quote}
\small
\begin{verbatim}
>>> sorted(counted_S.elements())
['a', 'a', 'e', 'e', 'f', 'g', 'g', 'g', 'i', 'l', 'n', 'n', 'o', 'r']
\end{verbatim}
\end{quote}

As a subclass of \lit{dict}, \lit{Counter} has specialized the
\lit{update()} method use the plus (\lit{+}) operator, and will do
exactly what we require to implement the method in our notation
written as $\oplus$. Unfortunately for our work, the \lit{subtract()}
function allows negative quantities,\footnote{The subclassed
\lit{update()} also allows for negative quantities, but when we are
adding objects whose count is greater than zero, there is no risk
of getting a negative result.} which means we will need to modify
it slightly in our subclass for it to be an implementation of
$\ominus$.

Figure~\ref{fig:countermods} code (with most comments removed for bevity)
that accomplishes the following in a class named \lit{CountedWord}:

\begin{enumerate}
\item As a subclass of \lit{Counter}, we get to use the builtin
methods.

\item In keeping with the spirit of the \lit{Counter} implementation,
we have superseded the meanings in the original class, so that $a - b$ does
not modify $a$, and $a -= b$ is provided for the cases where that is
desired.

\item We have provided a \verb|__str__()| operator that returns the
sorted string of the characters in the counter. This is generally the
most useful case if we want to, in effect, use a \lit{CountedWord} as 
a key. 

\end{enumerate}

\begin{figure}
\begin{framed}
\begin{quote}
\footnotesize
\begin{verbatim}
@total_ordering
class CountedWord(collections.Counter):

    def __init__(self, o:object):
        super().__init__(o)
        self.as_str = "".join(sorted(self.elements()))


    def __eq__(self, other:Union[CountedWord,str]) -> bool:
        if isinstance(other, str): other = CountedWord(other)
        return self == other


    def __le__(self, other:Union[CountedWord,str]) -> bool:
        """
        if shred1 <= shred2, then shred1 is in shred2
        """
        if isinstance(other, str): other=Counter(other)
        return all(other.get(c, 0) >= v for c, v in self.items())


    def __isub__(self, other:CountedWord) -> None:
        """
        shred1 -= shred2 is just a short way of writing subtract.
        """
        if isinstance(other, str): other = CountedWord(other)
        if other <= self:
            self.subtract(other.metrics)
            self.as_str = "".join(sorted(self.elements()))
        else:
            raise ValueError('RHS not <= LHS')


    def __sub__(self, other:CountedWord) -> CountedWord:
        new_word = copy.copy(self)
        new_word -= other
        return new_word


    def __str__(self) -> str:
        return self.as_str
\end{verbatim}
\end{quote}
\end{framed}
\normalsize
\caption{Example code for derived \lit{Counter} class}
\label{fig:countermods}
\end{figure}

\end{document}




























